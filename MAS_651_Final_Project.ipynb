{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brunosavoca/ml-finalproject-um/blob/main/MAS_651_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n"
      ],
      "metadata": {
        "id": "Fb2rcxRB-NcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSeqLhQZ9rBO"
      },
      "outputs": [],
      "source": [
        "app = pd.read_csv('card_application_record.csv')\n",
        "credit = pd.read_csv('card_credit_record.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# merging tables on column ID\n",
        "df = pd.merge(app, credit, on='ID')"
      ],
      "metadata": {
        "id": "cxUict4s-TjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "hTyWK2xUL3k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping column ID - not needed\n",
        "df = df.drop(['ID'], axis=1)"
      ],
      "metadata": {
        "id": "zA8ijecL-gSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "q5Zn1vx--2iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # checking for NaN\n",
        " df.isna().sum()"
      ],
      "metadata": {
        "id": "0k284lOQH58j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping column OCCUPATION_TYPE - too many NaN to be significant\n",
        "df = df.drop('OCCUPATION_TYPE', axis=1)\n"
      ],
      "metadata": {
        "id": "jTLD1ibU_Yoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " df.isna().sum()"
      ],
      "metadata": {
        "id": "TgWrPdeF_xAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n"
      ],
      "metadata": {
        "id": "-1Iiqpg6-3f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['STATUS'].value_counts()"
      ],
      "metadata": {
        "id": "Au40CtDtKlTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# redefine df with only some columns\n",
        "df = df[['CODE_GENDER', 'AMT_INCOME_TOTAL', 'NAME_EDUCATION_TYPE', 'STATUS']]\n"
      ],
      "metadata": {
        "id": "zbJQfqFMLYuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(10)"
      ],
      "metadata": {
        "id": "Nto0pYbARDFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['NAME_EDUCATION_TYPE'].value_counts()"
      ],
      "metadata": {
        "id": "xdZLemKsRFBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dictionary to map categories to numbers\n",
        "edu_map = {'Academic degree': 1, 'Lower secondary': 2, 'Secondary / secondary special': 3, 'Incomplete higher': 4, 'Higher education': 5}\n",
        "\n",
        "# replace category names with numbers\n",
        "df['EDUCATION_NUM'] = df['NAME_EDUCATION_TYPE'].replace(edu_map)"
      ],
      "metadata": {
        "id": "whVM2ablRN7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['CODE_GENDER'].value_counts()"
      ],
      "metadata": {
        "id": "vpelk39pv8ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dictionary to map categories to numbers\n",
        "gender_map = {'F': 1, 'M': 0}\n",
        "\n",
        "# replace category names with numbers\n",
        "df['GENDER_NUM'] = df['CODE_GENDER'].replace(gender_map)"
      ],
      "metadata": {
        "id": "H4ynJYopv_Nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['STATUS'].value_counts()"
      ],
      "metadata": {
        "id": "zz8c_nZHzqeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dictionary to map categories to numbers\n",
        "status_map = {'C': 6, 'X': 7}\n",
        "\n",
        "# replace category names with numbers\n",
        "df['STATUS'] = df['STATUS'].replace(status_map)"
      ],
      "metadata": {
        "id": "NBVtEx0Aznof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['GENDER_NUM','AMT_INCOME_TOTAL', 'EDUCATION_NUM', 'STATUS']]"
      ],
      "metadata": {
        "id": "-xnTt_faRntz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "RGeOweHkRuci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining threshold"
      ],
      "metadata": {
        "id": "bOTRa2bhe9g4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "qZvUFZ6X3dt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['GENDER_NUM'] = df['GENDER_NUM'].astype(int)\n",
        "df['AMT_INCOME_TOTAL'] = df['AMT_INCOME_TOTAL'].astype(int)\n",
        "df['EDUCATION_NUM'] = df['EDUCATION_NUM'].astype(int)\n",
        "df['STATUS'] = df['STATUS'].astype(int)"
      ],
      "metadata": {
        "id": "tkrrgiNsysPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['STATUS'].value_counts()"
      ],
      "metadata": {
        "id": "j2oiCz8IBA6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert 'AMT_INCOME_TOTAL' column to float\n",
        "df['AMT_INCOME_TOTAL'] = df['AMT_INCOME_TOTAL'].astype(float)\n",
        "\n",
        "# convert 'EDUCATION_NUM' column to float\n",
        "df['EDUCATION_NUM'] = df['EDUCATION_NUM'].astype(float)\n",
        "\n",
        "# define thresholds\n",
        "income_threshold = 70000\n",
        "edu_threshold = 4\n",
        "status_threshold = 5\n",
        "\n",
        "# define scoring function\n",
        "def score_row(row):\n",
        "    income_score = (row['AMT_INCOME_TOTAL'] - income_threshold) / income_threshold\n",
        "    edu_score = (row['EDUCATION_NUM'] - edu_threshold) / edu_threshold\n",
        "    status_score = (status_threshold - row['STATUS']) / status_threshold\n",
        "    \n",
        "    score = (income_score + edu_score + status_score) / 3\n",
        "        \n",
        "    return score\n",
        "# apply scoring function to each row\n",
        "df['SCORE'] = df.apply(score_row, axis=1)"
      ],
      "metadata": {
        "id": "x_woHhrNCygw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "id": "8kd1SzAHDKaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "bFZaw8pFUrZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Scores* above 0.8 represent 'good clients', while scores below 0.8 represent 'bad clients'."
      ],
      "metadata": {
        "id": "UFjun04h1Kcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_initial = 0.8 \n",
        "df['APPROVED'] = df['SCORE'].apply(lambda x: 1 if x > threshold_initial else 0)"
      ],
      "metadata": {
        "id": "JadZkDEten0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 good client (approved), 0 bad client (not approved)\n",
        "sns.countplot(x='APPROVED',data=df, palette='BuGn')\n",
        "plt.show()\n",
        "plt.savefig('count_plot')\n"
      ],
      "metadata": {
        "id": "HfnJGRoIdNir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 = Male, 1 = Female; 0 = not approved, 1 = approved\n",
        "table=pd.crosstab(df.GENDER_NUM,df.APPROVED)\n",
        "table.div(table.sum(1).astype(float), axis=0).plot(kind='bar',\n",
        "stacked=True, color=['teal','turquoise'] )\n",
        "plt.title('Stacked Bar Chart of Gender vs Approval Status')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Approval Status')\n",
        "plt.savefig('Gender_Approval')"
      ],
      "metadata": {
        "id": "mdhUpBIkdUiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Academic degree': 1, 'Lower secondary': 2, 'Secondary / secondary special': 3, 'Incomplete higher': 4, 'Higher education': 5; 0 = not approved, 1 = approved\n",
        "table=pd.crosstab(df.EDUCATION_NUM,df.APPROVED)\n",
        "table.div(table.sum(1).astype(float), axis=0).plot(kind='bar',\n",
        "stacked=True, color=['teal','turquoise'] )\n",
        "plt.title('Stacked Bar Chart of Education Level vs Approval Status')\n",
        "plt.xlabel('Education Level')\n",
        "plt.ylabel('Approval Status')\n",
        "plt.savefig('Education_Approval')"
      ],
      "metadata": {
        "id": "jjjOJxZYhkap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0: 1-29 days past due, 1: 30-59 days past due, 2: 60-89 days overdue, 3: 90-119 days overdue, 4: 120-149 days overdue, \n",
        "# 5: Overdue or bad debts, write-offs for more than 150 days, 6: paid off that month, 7: No loan for the month\n",
        "\n",
        "table=pd.crosstab(df.STATUS,df.APPROVED)\n",
        "table.div(table.sum(1).astype(float), axis=0).plot(kind='bar',\n",
        "stacked=True, color=['teal','turquoise'] )\n",
        "plt.title('Stacked Bar Chart of Status vs Approval Status')\n",
        "plt.xlabel('Status')\n",
        "plt.ylabel('Approval Status')\n",
        "plt.savefig('Status_Approval')"
      ],
      "metadata": {
        "id": "mun8QLHXh5p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MODEL SELECTION"
      ],
      "metadata": {
        "id": "JFYgtUW31CFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic**"
      ],
      "metadata": {
        "id": "rfqrA8Rc1EhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['APPROVED']\n",
        "X = df.drop(['APPROVED'], axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)"
      ],
      "metadata": {
        "id": "LQNpSJ2Tg8ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "guoYYWqHgxBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = logreg.predict(X_test)"
      ],
      "metadata": {
        "id": "P1dXl_tlgzNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
      ],
      "metadata": {
        "id": "bI-fYxP4g2QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGB**\n"
      ],
      "metadata": {
        "id": "z8yifJz0LpHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#overwriting 'SCORE' column to define a threshold\n",
        "\n",
        "threshold = 1 # threshold value can be adjusted based on your data\n",
        "df['PRE_APPROVED'] = df['SCORE'].apply(lambda x: 1 if x > threshold and np.random.rand() > 0.65 else 0)\n"
      ],
      "metadata": {
        "id": "FvEdTMciBF9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "id": "vM6KdVM6LesK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dummy variables\n",
        "encoded_data = pd.get_dummies(df)\n",
        "encoded_data.head()"
      ],
      "metadata": {
        "id": "IAC3UtgnLEwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['PRE_APPROVED'], axis=1)\n",
        "y = df['PRE_APPROVED']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n"
      ],
      "metadata": {
        "id": "krfhBDSZSZOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "model = xgb.XGBClassifier(max_depth=4,\n",
        "                        subsample=0.9,\n",
        "                        objective='binary:logistic',\n",
        "                        n_estimators=200,\n",
        "                        learning_rate = 0.1)\n",
        "\n",
        "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
        "\n",
        "model.fit(X_train, y_train, early_stopping_rounds=10, eval_metric=[\"error\", \"logloss\"], eval_set=eval_set, verbose=True)"
      ],
      "metadata": {
        "id": "0i8ARfpjLn75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# make predictions for test data\n",
        "y_pred = model.predict(X_test)\n",
        "predictions = [round(value) for value in y_pred]"
      ],
      "metadata": {
        "id": "f8qcmT4LL6zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "metadata": {
        "id": "zSH6R_rxMAkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = ['Logistic Regression', 'XGBoost Classifier']\n",
        "accuracies = [0.8655, 0.9385]\n",
        "\n",
        "c = ['Green', 'Lightgreen']\n",
        "\n",
        "plt.bar(models, accuracies, color = c)\n",
        "plt.title('Accuracy Results')"
      ],
      "metadata": {
        "id": "RPLp6KJLk3f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# get the feature importance\n",
        "importance = model.feature_importances_\n",
        "\n",
        "# get the names of the features\n",
        "features = X_train.columns\n",
        "\n",
        "# create a dataframe to store the feature importance values\n",
        "df = pd.DataFrame({'features': features, 'importance': importance})\n",
        "\n",
        "# sort the dataframe by importance\n",
        "df = df.sort_values(by='importance', ascending=False)\n",
        "\n",
        "# print the top 10 most influential variables\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "id": "gAc4hdLnwaaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lazypredict\n"
      ],
      "metadata": {
        "id": "NfUlofq5Ic17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "from lazypredict.Supervised import LazyRegressor\n",
        "\n",
        "\n",
        "# Initialize and fit the LazyRegressor model\n",
        "#reg = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "#models, predictions = reg. fit(X_train, X_test, y_train, y_test)\n",
        "# Print models\n",
        "#print(tabulate(models, headers='keys', tablefmt='psql'))"
      ],
      "metadata": {
        "id": "8n9rfPP1HxJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gt1DQSJcHxhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EwX0nY7XKDa-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}